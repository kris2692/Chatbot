{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "HParams = namedtuple(\n",
    "  \"HParams\",\n",
    "  [\n",
    "    \"batch_size\",\n",
    "    \"embedding_dim\",\n",
    "    \"eval_batch_size\",\n",
    "    \"learning_rate\",\n",
    "    \"max_context_len\",\n",
    "    \"max_utterance_len\",\n",
    "    \"optimizer\",\n",
    "    \"rnn_dim\",\n",
    "    \"vocab_size\",\n",
    "    \"glove_path\",\n",
    "    \"vocab_path\"\n",
    "  ])\n",
    "\n",
    "def create_hyperparameters():\n",
    "    return HParams(\n",
    "    batch_size=128,\n",
    "    eval_batch_size=8,\n",
    "    vocab_size=91620,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.001,\n",
    "    embedding_dim=100,\n",
    "    max_context_len=160,\n",
    "    max_utterance_len=80,\n",
    "    glove_path=None,\n",
    "    vocab_path=None,\n",
    "    rnn_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.py\n",
    "\n",
    "import functools\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "\n",
    "\n",
    "def create_evaluation_metrics():\n",
    "    evaluation_metrics = {}\n",
    "    for k in [1, 2, 5, 10]:\n",
    "        evaluation_metrics[\"recall_@_%d\" % k] = MetricSpec(metric_fn=functools.partial(\n",
    "            tf.contrib.metrics.streaming_sparse_recall_at_k,\n",
    "            k=k))\n",
    "    return evaluation_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# dual_encoder.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dual_encoder_model(\n",
    "    hparams,\n",
    "    mode,\n",
    "    context,\n",
    "    context_len,\n",
    "    utterance,\n",
    "    utterance_len,\n",
    "    targets,\n",
    "    ):\n",
    "\n",
    "    #print ('targets', targets)\n",
    "\n",
    "  # initialize word embeddings with random initialization\n",
    "\n",
    "    tf.logging.info('No glove/vocab path specificed, starting with random embeddings.'\n",
    "                    )\n",
    "    init = tf.random_uniform_initializer(-0.25, 0.25)\n",
    "\n",
    "    word_embeddings = tf.get_variable('word_embeddings',\n",
    "            shape=[hparams.vocab_size, hparams.embedding_dim],\n",
    "            initializer=init)\n",
    "\n",
    "  # Embedding context and utterance\n",
    "\n",
    "    context_embedded = tf.nn.embedding_lookup(word_embeddings, context,\n",
    "            name='contect_embedding')\n",
    "    utterance_embedded = tf.nn.embedding_lookup(word_embeddings,\n",
    "            utterance, name='utterrance_embedding')\n",
    "\n",
    "  # Build the RNN\n",
    "\n",
    "    with tf.variable_scope('rnn') as vs:\n",
    "\n",
    "    # LSTm cell usage\n",
    "\n",
    "        lstm_cell = tf.contrib.rnn.LSTMCell(hparams.rnn_dim,\n",
    "                forget_bias=2.0, use_peepholes=True,\n",
    "                state_is_tuple=True)\n",
    "\n",
    "    # pass context and utterrances to network\n",
    "\n",
    "        (rnn__lstm_outputs, rnn_lstm_states) = \\\n",
    "            tf.nn.dynamic_rnn(lstm_cell, tf.concat([context_embedded,\n",
    "                              utterance_embedded], 0),\n",
    "                              sequence_length=tf.concat([context_len,\n",
    "                              utterance_len], 0), dtype=tf.float32)\n",
    "        (context_encoded, response_encoded) = \\\n",
    "            tf.split(rnn_lstm_states.h, 2, 0)\n",
    "\n",
    "    with tf.variable_scope('prediction') as vs:\n",
    "        W = tf.get_variable('W', shape=[hparams.rnn_dim,\n",
    "                            hparams.rnn_dim],\n",
    "                            initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "    # perferming elementary prediction operation by multiplying c * W\n",
    "\n",
    "        r_dash = tf.matmul(context_encoded, W)\n",
    "        r_dash = tf.expand_dims(r_dash, 2)\n",
    "        response_encoded = tf.expand_dims(response_encoded, 2)\n",
    "\n",
    "    # Dot product between generated response and actual response\n",
    "    # (c * W) * r\n",
    "\n",
    "        logits = tf.matmul(r_dash, response_encoded, True)\n",
    "        logits = tf.squeeze(logits, [2])\n",
    "\n",
    "    # logit to probablities\n",
    "\n",
    "        probabilities = tf.sigmoid(logits)\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            return (probabilities, None)\n",
    "\n",
    "    # Calculate the binary cross-entropy loss\n",
    "\n",
    "        loss = \\\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.to_float(targets),\n",
    "                logits=logits)\n",
    "\n",
    "  # Mean loss across the batch of examples\n",
    "\n",
    "    mean_loss = tf.reduce_mean(loss, name='mean_loss')\n",
    "    return (probabilities, mean_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# model.py\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_feature_ids(\n",
    "    features,\n",
    "    key,\n",
    "    key_leng,\n",
    "    max_len,\n",
    "    ):\n",
    "    ids = features[key]\n",
    "    len_of_id = tf.squeeze(features[key_leng], [1])\n",
    "    len_of_id = tf.minimum(len_of_id, tf.constant(max_len,\n",
    "                           dtype=tf.int64))\n",
    "    return (ids, len_of_id)\n",
    "\n",
    "\n",
    "def start_training_operation(loss, hyperparams):\n",
    "    training_operation = tf.contrib.layers.optimize_loss(loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=hyperparams.learning_rate,\n",
    "            clip_gradients=10.0, optimizer=hyperparams.optimizer)\n",
    "    return training_operation\n",
    "\n",
    "\n",
    "def generate_model(hparams, model_impl):\n",
    "\n",
    "    def model_function(features, targets, mode):\n",
    "        #print ('===========Chatbot-RNN & LSTM===============')\n",
    "        (context, context_len) = get_feature_ids(features, 'context',\n",
    "                'context_len', hparams.max_context_len)\n",
    "\n",
    "        (utterance, utterance_len) = get_feature_ids(features,\n",
    "                'utterance', 'utterance_len', hparams.max_utterance_len)\n",
    "        \n",
    "        \n",
    "        if targets!= None:\n",
    "            batch_size = targets.get_shape().as_list()[0]\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            (probs, loss) = model_impl(\n",
    "                hparams,\n",
    "                mode,\n",
    "                context,\n",
    "                context_len,\n",
    "                utterance,\n",
    "                utterance_len,\n",
    "                targets,\n",
    "                )\n",
    "            train_op = start_training_operation(loss, hparams)\n",
    "            return (probs, loss, train_op)\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            (probs, loss) = model_impl(\n",
    "                hparams,\n",
    "                mode,\n",
    "                context,\n",
    "                context_len,\n",
    "                utterance,\n",
    "                utterance_len,\n",
    "                None,\n",
    "                )\n",
    "            return (probs, 0.0, None)\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.EVAL:\n",
    "\n",
    "      # We have 10 exampels per record, so we accumulate them\n",
    "\n",
    "            all_contexts = [context]\n",
    "            all_context_lens = [context_len]\n",
    "            all_utterances = [utterance]\n",
    "            all_utterance_lens = [utterance_len]\n",
    "            all_targets = [tf.ones([batch_size, 1], dtype=tf.int64)]\n",
    "\n",
    "            for i in range(9):\n",
    "                (distractor, distractor_len) = \\\n",
    "                    get_feature_ids(features,\n",
    "                                    'distractor_{}'.format(i),\n",
    "                                    'distractor_{}_len'.format(i),\n",
    "                                    hparams.max_utterance_len)\n",
    "                all_contexts.append(context)\n",
    "                all_context_lens.append(context_len)\n",
    "                all_utterances.append(distractor)\n",
    "                all_utterance_lens.append(distractor_len)\n",
    "                all_targets.append(tf.zeros([batch_size, 1],\n",
    "                                   dtype=tf.int64))\n",
    "\n",
    "            (probs, loss) = model_impl(\n",
    "                hparams,\n",
    "                mode,\n",
    "                tf.concat(all_contexts, 0),\n",
    "                tf.concat(all_context_lens, 0),\n",
    "                tf.concat(all_utterances, 0),\n",
    "                tf.concat(all_utterance_lens, 0),\n",
    "                tf.concat(all_targets, 0),\n",
    "                )\n",
    "\n",
    "            split_probs = tf.split(probs, 10, 0)\n",
    "            shaped_probs = tf.concat(split_probs, 1)\n",
    "\n",
    "      # Add summaries\n",
    "\n",
    "            tf.summary.histogram('eval_correct_probs_hist',\n",
    "                                 split_probs[0])\n",
    "            tf.summary.scalar('eval_correct_probs_average',\n",
    "                              tf.reduce_mean(split_probs[0]))\n",
    "            tf.summary.histogram('eval_incorrect_probs_hist',\n",
    "                                 split_probs[1])\n",
    "            tf.summary.scalar('eval_incorrect_probs_average',\n",
    "                              tf.reduce_mean(split_probs[1]))\n",
    "\n",
    "            return (shaped_probs, loss, None)\n",
    "\n",
    "    return model_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.py\n",
    "\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "TEXT_FEATURE_SIZE = 160\n",
    "\n",
    "\n",
    "def create_input_fn(\n",
    "    mode,\n",
    "    input_files,\n",
    "    batch_size,\n",
    "    num_epochs,\n",
    "    ):\n",
    "\n",
    "    def input_fn():\n",
    "        columns_attribs = []\n",
    "        columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='context'\n",
    "                               , dimension=TEXT_FEATURE_SIZE,\n",
    "                               dtype=tf.int64))\n",
    "        columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='context_len'\n",
    "                               , dimension=1, dtype=tf.int64))\n",
    "        columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='utterance'\n",
    "                               , dimension=TEXT_FEATURE_SIZE,\n",
    "                               dtype=tf.int64))\n",
    "        columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='utterance_len'\n",
    "                               , dimension=1, dtype=tf.int64))\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "\n",
    "      # During training we have a label feature\n",
    "\n",
    "            columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='label'\n",
    "                                   , dimension=1, dtype=tf.int64))\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.EVAL:\n",
    "\n",
    "      # During evaluation we have distractors\n",
    "\n",
    "            for i in range(9):\n",
    "                columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='distractor_{}'.format(i),\n",
    "                        dimension=TEXT_FEATURE_SIZE, dtype=tf.int64))\n",
    "                columns_attribs.append(tf.contrib.layers.real_valued_column(column_name='distractor_{}_len'.format(i),\n",
    "                        dimension=1, dtype=tf.int64))\n",
    "\n",
    "        features = \\\n",
    "            tf.contrib.layers.create_feature_spec_for_parsing(set(columns_attribs))\n",
    "\n",
    "        feature_map = tf.contrib.learn.io.read_batch_features(\n",
    "            file_pattern=input_files,\n",
    "            batch_size=batch_size,\n",
    "            features=features,\n",
    "            reader=tf.TFRecordReader,\n",
    "            randomize_input=True,\n",
    "            num_epochs=num_epochs,\n",
    "            queue_capacity=200000 + batch_size * 10,\n",
    "            name='read_batch_features_{}'.format(mode),\n",
    "            )\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "            target = feature_map.pop('label')\n",
    "        else:\n",
    "\n",
    "      # In evaluation we have 10 classes (utterances).\n",
    "      # The first one (index 0) is always the correct one\n",
    "\n",
    "            target = tf.zeros([batch_size, 1], dtype=tf.int64)\n",
    "        return (feature_map, target)\n",
    "\n",
    "    return input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_task_type': None, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f46646d1828>, '_model_dir': '/home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531', '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_is_chief': True, '_task_id': 0, '_evaluation_master': '', '_environment': 'local', '_save_summary_steps': 100, '_num_worker_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0}\n",
      "===========Chatbot-RNN & LSTM===============\n",
      "targets Tensor(\"read_batch_features_train/fifo_queue_Dequeue:2\", shape=(128, 1), dtype=int64)\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.870406, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.99655\n",
      "INFO:tensorflow:loss = 0.702607, step = 101 (50.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00612\n",
      "INFO:tensorflow:loss = 0.69147, step = 201 (49.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00614\n",
      "INFO:tensorflow:loss = 0.681146, step = 301 (49.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00326\n",
      "INFO:tensorflow:loss = 0.683632, step = 401 (49.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00152\n",
      "INFO:tensorflow:loss = 0.706286, step = 501 (49.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00285\n",
      "INFO:tensorflow:loss = 0.691765, step = 601 (49.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00368\n",
      "INFO:tensorflow:loss = 0.648649, step = 701 (49.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00431\n",
      "INFO:tensorflow:loss = 0.708302, step = 801 (49.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00433\n",
      "INFO:tensorflow:loss = 0.678682, step = 901 (49.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99892\n",
      "INFO:tensorflow:loss = 0.654299, step = 1001 (50.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00306\n",
      "INFO:tensorflow:loss = 0.647267, step = 1101 (49.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00211\n",
      "INFO:tensorflow:loss = 0.645643, step = 1201 (49.947 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1203 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.98511\n",
      "INFO:tensorflow:loss = 0.676417, step = 1301 (50.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00238\n",
      "INFO:tensorflow:loss = 0.629876, step = 1401 (49.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00495\n",
      "INFO:tensorflow:loss = 0.65106, step = 1501 (49.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00173\n",
      "INFO:tensorflow:loss = 0.67378, step = 1601 (49.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0014\n",
      "INFO:tensorflow:loss = 0.682739, step = 1701 (49.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00474\n",
      "INFO:tensorflow:loss = 0.575137, step = 1801 (49.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00234\n",
      "INFO:tensorflow:loss = 0.599393, step = 1901 (49.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00425\n",
      "INFO:tensorflow:loss = 0.592746, step = 2001 (49.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00238\n",
      "INFO:tensorflow:loss = 0.577966, step = 2101 (49.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00146\n",
      "INFO:tensorflow:loss = 0.598942, step = 2201 (49.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00351\n",
      "INFO:tensorflow:loss = 0.624242, step = 2301 (49.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0012\n",
      "INFO:tensorflow:loss = 0.622828, step = 2401 (49.970 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2404 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.99021\n",
      "INFO:tensorflow:loss = 0.63154, step = 2501 (50.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00139\n",
      "INFO:tensorflow:loss = 0.571992, step = 2601 (49.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.98972\n",
      "INFO:tensorflow:loss = 0.590174, step = 2701 (50.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00079\n",
      "INFO:tensorflow:loss = 0.600587, step = 2801 (49.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99882\n",
      "INFO:tensorflow:loss = 0.519518, step = 2901 (50.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00129\n",
      "INFO:tensorflow:loss = 0.598798, step = 3001 (49.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00144\n",
      "INFO:tensorflow:loss = 0.521862, step = 3101 (49.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00231\n",
      "INFO:tensorflow:loss = 0.657838, step = 3201 (49.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0029\n",
      "INFO:tensorflow:loss = 0.575251, step = 3301 (49.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99966\n",
      "INFO:tensorflow:loss = 0.60044, step = 3401 (50.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00286\n",
      "INFO:tensorflow:loss = 0.558604, step = 3501 (49.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00118\n",
      "INFO:tensorflow:loss = 0.603365, step = 3601 (49.971 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3604 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.98834\n",
      "INFO:tensorflow:loss = 0.532253, step = 3701 (50.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00156\n",
      "INFO:tensorflow:loss = 0.552703, step = 3801 (49.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99969\n",
      "INFO:tensorflow:loss = 0.513514, step = 3901 (50.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.97056\n",
      "INFO:tensorflow:loss = 0.546888, step = 4001 (50.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.94807\n",
      "INFO:tensorflow:loss = 0.586422, step = 4101 (51.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99914\n",
      "INFO:tensorflow:loss = 0.532976, step = 4201 (50.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00022\n",
      "INFO:tensorflow:loss = 0.501331, step = 4301 (49.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00224\n",
      "INFO:tensorflow:loss = 0.494703, step = 4401 (49.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00196\n",
      "INFO:tensorflow:loss = 0.556111, step = 4501 (49.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99742\n",
      "INFO:tensorflow:loss = 0.508066, step = 4601 (50.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00174\n",
      "INFO:tensorflow:loss = 0.538797, step = 4701 (49.957 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.99151\n",
      "INFO:tensorflow:loss = 0.526136, step = 4801 (50.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00958\n",
      "INFO:tensorflow:loss = 0.498914, step = 4901 (49.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0089\n",
      "INFO:tensorflow:loss = 0.527755, step = 5001 (49.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00662\n",
      "INFO:tensorflow:loss = 0.597621, step = 5101 (49.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00234\n",
      "INFO:tensorflow:loss = 0.465402, step = 5201 (49.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00658\n",
      "INFO:tensorflow:loss = 0.522465, step = 5301 (49.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00705\n",
      "INFO:tensorflow:loss = 0.54203, step = 5401 (49.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00646\n",
      "INFO:tensorflow:loss = 0.562328, step = 5501 (49.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00716\n",
      "INFO:tensorflow:loss = 0.516319, step = 5601 (49.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00965\n",
      "INFO:tensorflow:loss = 0.459335, step = 5701 (49.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00238\n",
      "INFO:tensorflow:loss = 0.529706, step = 5801 (49.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00424\n",
      "INFO:tensorflow:loss = 0.59195, step = 5901 (49.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00333\n",
      "INFO:tensorflow:loss = 0.535564, step = 6001 (49.917 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6004 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.9909\n",
      "INFO:tensorflow:loss = 0.516075, step = 6101 (50.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00232\n",
      "INFO:tensorflow:loss = 0.540292, step = 6201 (49.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00372\n",
      "INFO:tensorflow:loss = 0.525541, step = 6301 (49.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.550617, step = 6401 (50.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99779\n",
      "INFO:tensorflow:loss = 0.508454, step = 6501 (50.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00425\n",
      "INFO:tensorflow:loss = 0.58267, step = 6601 (49.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00047\n",
      "INFO:tensorflow:loss = 0.553195, step = 6701 (49.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00475\n",
      "INFO:tensorflow:loss = 0.494295, step = 6801 (49.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00276\n",
      "INFO:tensorflow:loss = 0.453959, step = 6901 (49.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99996\n",
      "INFO:tensorflow:loss = 0.483793, step = 7001 (50.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00153\n",
      "INFO:tensorflow:loss = 0.510505, step = 7101 (49.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00335\n",
      "INFO:tensorflow:loss = 0.457296, step = 7201 (49.917 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7205 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.98983\n",
      "INFO:tensorflow:loss = 0.481441, step = 7301 (50.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00416\n",
      "INFO:tensorflow:loss = 0.565648, step = 7401 (49.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00296\n",
      "INFO:tensorflow:loss = 0.450858, step = 7501 (49.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00287\n",
      "INFO:tensorflow:loss = 0.541981, step = 7601 (49.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0031\n",
      "INFO:tensorflow:loss = 0.498727, step = 7701 (49.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00578\n",
      "INFO:tensorflow:loss = 0.50394, step = 7801 (49.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00143\n",
      "INFO:tensorflow:loss = 0.430721, step = 7901 (49.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00436\n",
      "INFO:tensorflow:loss = 0.582239, step = 8001 (49.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00447\n",
      "INFO:tensorflow:loss = 0.465969, step = 8101 (49.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00142\n",
      "INFO:tensorflow:loss = 0.563418, step = 8201 (49.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00131\n",
      "INFO:tensorflow:loss = 0.475983, step = 8301 (49.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00108\n",
      "INFO:tensorflow:loss = 0.460371, step = 8401 (49.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8407 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.99031\n",
      "INFO:tensorflow:loss = 0.496365, step = 8501 (50.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00475\n",
      "INFO:tensorflow:loss = 0.468827, step = 8601 (49.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.0024\n",
      "INFO:tensorflow:loss = 0.476833, step = 8701 (49.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99872\n",
      "INFO:tensorflow:loss = 0.534108, step = 8801 (50.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00027\n",
      "INFO:tensorflow:loss = 0.420964, step = 8901 (49.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.002\n",
      "INFO:tensorflow:loss = 0.548742, step = 9001 (49.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.99975\n",
      "INFO:tensorflow:loss = 0.477003, step = 9101 (50.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00158\n",
      "INFO:tensorflow:loss = 0.482904, step = 9201 (49.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00383\n",
      "INFO:tensorflow:loss = 0.451945, step = 9301 (49.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00041\n",
      "INFO:tensorflow:loss = 0.450708, step = 9401 (49.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00196\n",
      "INFO:tensorflow:loss = 0.534328, step = 9501 (49.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00124\n",
      "INFO:tensorflow:loss = 0.508124, step = 9601 (49.969 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9608 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.99001\n",
      "INFO:tensorflow:loss = 0.507794, step = 9701 (50.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00061\n",
      "INFO:tensorflow:loss = 0.441937, step = 9801 (49.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.98648\n",
      "INFO:tensorflow:loss = 0.421786, step = 9901 (50.342 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.491828.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_task_type': None, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f46346baa20>, '_model_dir': '/home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531', '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_is_chief': True, '_task_id': 0, '_evaluation_master': '', '_environment': 'local', '_save_summary_steps': 100, '_num_worker_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0}\n",
      "===========Chatbot-RNN & LSTM===============\n",
      "targets Tensor(\"read_batch_features_train/fifo_queue_Dequeue:2\", shape=(128, 1), dtype=int64)\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "===========Chatbot-RNN & LSTM===============\n",
      "targets Tensor(\"concat_4:0\", shape=(80, 1), dtype=int64)\n",
      "INFO:tensorflow:No glove/vocab path specificed, starting with random embeddings.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-03-22:28:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt-10001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-03-22:33:06\n",
      "INFO:tensorflow:Saving dict for global step 10001: global_step = 10001, loss = 0.505161, recall_@_1 = 0.477300613497, recall_@_10 = 1.0, recall_@_2 = 0.660736196319, recall_@_5 = 0.900869120654\n",
      "INFO:tensorflow:Validation (step 10001): global_step = 10001, recall_@_10 = 1.0, recall_@_2 = 0.660736196319, recall_@_1 = 0.477300613497, loss = 0.505161, recall_@_5 = 0.900869120654\n",
      "INFO:tensorflow:loss = 0.46775, step = 10001\n",
      "INFO:tensorflow:Saving checkpoints for 10010 into /home/babyeagle/MachineLearning/Project/chatbot-rnn and lstm/runs/1525381531/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.381535.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babyeagle/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# train\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "\n",
    "TIMESTAMP = int(time.time())\n",
    "\n",
    "MODEL_DIR = os.path.abspath(os.path.join('./runs', str(TIMESTAMP)))\n",
    "\n",
    "TRAIN_FILE = os.path.abspath(os.path.join('./data', 'train.tfrecords'))\n",
    "VALIDATION_FILE = os.path.abspath(os.path.join('./data',\n",
    "                                  'validation.tfrecords'))\n",
    "\n",
    "tf.logging.set_verbosity(20)\n",
    "\n",
    "hyperparams = create_hyperparameters()\n",
    "\n",
    "tf_model_function = generate_model(hyperparams,\n",
    "            model_impl=dual_encoder_model)\n",
    "\n",
    "tf_estimator = \\\n",
    "        tf.contrib.learn.Estimator(model_fn=tf_model_function,\n",
    "                                   model_dir=MODEL_DIR,\n",
    "                                   config=tf.contrib.learn.RunConfig())\n",
    "\n",
    "input_training_function = \\\n",
    "        create_input_fn(mode=tf.contrib.learn.ModeKeys.TRAIN,\n",
    "                                  input_files=[TRAIN_FILE],\n",
    "                                  batch_size=hyperparams.batch_size,\n",
    "                                  num_epochs=None)\n",
    "\n",
    "input_evaluation_function = \\\n",
    "        create_input_fn(mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "                                  input_files=[VALIDATION_FILE],\n",
    "                                  batch_size=hyperparams.eval_batch_size,\n",
    "                                  num_epochs=1)\n",
    "\n",
    "recallAtk_evaluation_metric = create_evaluation_metrics()\n",
    "\n",
    "monitor_recall = \\\n",
    "        tf.contrib.learn.monitors.ValidationMonitor(input_fn=input_evaluation_function,\n",
    "            every_n_steps=2000, metrics=recallAtk_evaluation_metric)\n",
    "\n",
    "tf_estimator.fit(input_fn=input_training_function, steps=30000,\n",
    "                     monitors=[])\n",
    "\n",
    "tf.app.run()\n",
    "\n",
    "sys.exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: hi\n",
      "hello [ 0.54939836]\n",
      "maybe [ 0.36490214]\n",
      "goodbye [ 0.39229482]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "def tokenizer_fn(iterator):\n",
    "    return (x.split(' ') for x in iterator)\n",
    "\n",
    "\n",
    "# Create vocabulary ourselves or load saved one\n",
    "if not \"./data/vocab_processor.bin\":\n",
    "    vp = tf.contrib.learn.preprocessing.VocabularyProcessor(100000)\n",
    "    vp.fit(open(\"./data/vocab_processor.bin\"))\n",
    "    vp.save('./data/vocab_processor.bin')\n",
    "else:\n",
    "    vp = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(\n",
    "    \"./data/vocab_processor.bin\")\n",
    "\n",
    "\n",
    "# Load your own data here\n",
    "\n",
    "INPUT_CONTEXT = 'hi'\n",
    "POTENTIAL_RESPONSES = ['hello', 'goodbye', 'maybe']\n",
    "\n",
    "\n",
    "def get_features(context, utterance):\n",
    "    context_matrix = np.array(list(vp.transform([context])))\n",
    "    utterance_matrix = np.array(list(vp.transform([utterance])))\n",
    "    context_len = len(context.split(\" \"))\n",
    "    utterance_len = len(utterance.split(\" \"))\n",
    "    features = {\n",
    "     \"context\": tf.convert_to_tensor(context_matrix, dtype=tf.int64),\n",
    "     \"context_len\": tf.constant(context_len, shape=[1,1], dtype=tf.int64),\n",
    "     \"utterance\": tf.convert_to_tensor(utterance_matrix, dtype=tf.int64),\n",
    "     \"utterance_len\": tf.constant(utterance_len, shape=[1,1], dtype=tf.int64),\n",
    "   }\n",
    "    return features, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hparams = create_hyperparameters()\n",
    "    model_fn = generate_model(hparams, model_impl=dual_encoder_model)\n",
    "    estimator = tf.contrib.learn.Estimator(model_fn=model_fn, model_dir='./runs/1525381531')\n",
    "    print(\"Context: {}\".format(INPUT_CONTEXT))\n",
    "    dict_final = {}\n",
    "    for r in POTENTIAL_RESPONSES:\n",
    "        prob = estimator.predict(input_fn=lambda: get_features(INPUT_CONTEXT, r))\n",
    "        dict_final[r] = next(prob)\n",
    "        #print(\"{}: {}\".format(r, next(prob)))\n",
    "    for k in dict_final:\n",
    "        print(k, dict_final[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
